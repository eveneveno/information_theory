\relax 
\providecommand\tcolorbox@label[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Information Measures}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Independence and Markov Chains}{1}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.1}{1}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.2 (Mutual Independence)}{1}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.3 (Pairwise Independence)}{1}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.4 (Conditional Independence)}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.5}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.6 (Markov Chain)}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.7}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.8}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.9}{2}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.10 (Markov subchains)}{2}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.12}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Shannon\IeC {\textquoteright }s Information Measures}{2}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.13 (Entropy)}{2}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.14 (Joint Entropy)}{3}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.15 (Conditional Entropy)}{3}}
\@writefile{toc}{\contentsline {paragraph}{Definition (Entropy of $Y$ conditioning on $x$)}{3}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.16}{3}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.17 (Mutual Information)}{4}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.18}{4}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.19}{4}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.20 (Conditional Mutual Information)}{4}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.21}{4}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.22}{4}}
\@writefile{toc}{\contentsline {paragraph}{Continuity of Shannon\IeC {\textquoteright }s Information Measures for Fixed Finite Alphabets}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Continuity of Shannon\IeC {\textquoteright }s Information Measures for Fixed Finite Alphabets}{5}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.23}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Chain Rules}{5}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.24 (Chain Rule for Entropy)}{5}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.25 (Chain Rule for Conditional Entropy)}{5}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.26 (Chain Rule for Mutual Information)}{6}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.27 (Chain Rule for Conditional Mutual Information)}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Informational Divergence}{6}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.28 (Informational Divergence)}{6}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 2.29 (Fundamental Inequality)}{7}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 2.30}{7}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.6.2 (Cover: Jensen's inequality )}{7}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.31 (Divergence Inequality)}{7}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.32 (Log-Sum Inequality)}{7}}
\@writefile{toc}{\contentsline {paragraph}{Example:}{7}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.33 (Pinsker's Inequality)}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}The Basic Inequalities}{8}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.34}{8}}
\@writefile{toc}{\contentsline {paragraph}{Corollary}{9}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.35}{9}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.36}{9}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.37}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Some Useful Information Inequalities}{9}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.38 (Conditioning Does Not Increase Entropy)}{9}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.39 (Independence Bound for Entropy)}{9}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.40}{10}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 2.41}{10}}
\@writefile{toc}{\contentsline {paragraph}{Corollary}{10}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.42 (Data Processing Theorem)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.43}{10}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 2.44}{11}}
\@writefile{toc}{\contentsline {paragraph}{Remark}{11}}
\@writefile{toc}{\contentsline {paragraph}{Remark}{11}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.47 (Fano's Inequality)}{11}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 2.48}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3}The $I$-Measure}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Preliminaries}{12}}
\@writefile{toc}{\contentsline {paragraph}{Example}{12}}
\@writefile{toc}{\contentsline {paragraph}{Definition 3.1 (Field)}{12}}
\@writefile{toc}{\contentsline {paragraph}{Definition 3.2 (Atoms)}{12}}
\@writefile{toc}{\contentsline {paragraph}{Definition 3.4}{12}}
\@writefile{toc}{\contentsline {paragraph}{Example 3.5}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The I-Measure for Two Random Variables}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Construction of the $I$-Measure $\mu ^{*}$}{12}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 3.6}{13}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 3.7}{13}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 3.8}{13}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 3.9}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}$\mu ^{*}$ Can Be Negative}{13}}
\@writefile{toc}{\contentsline {paragraph}{Example 3.10}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Information Diagrams}{14}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 3.11}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Examples of Applications}{14}}
\@writefile{toc}{\contentsline {paragraph}{Example 3.12 (Concavity of Entropy)}{14}}
\@writefile{toc}{\contentsline {paragraph}{Example 3.13 (Convexity of Mutual Information)}{15}}
\@writefile{toc}{\contentsline {paragraph}{Example 3.14 (Concavity of Mutual Information)}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Zero-Error Data Compression}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The Entropy Bound}{15}}
\@writefile{toc}{\contentsline {paragraph}{Definition 4.1}{15}}
\@writefile{toc}{\contentsline {paragraph}{Definition 4.2 (Uniquely Decodable Codes)}{15}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 4.4 (Kraft Inequality)}{15}}
\@writefile{toc}{\contentsline {paragraph}{Expected length of $\mathcal  {C}$}{16}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 4.6 (Entropy Bound)}{16}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 4.7}{17}}
\@writefile{toc}{\contentsline {paragraph}{Definition 4.8}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Prefix Codes}{17}}
\@writefile{toc}{\contentsline {paragraph}{Definition 4.9}{17}}
\@writefile{toc}{\contentsline {paragraph}{Code Tree for Prefix Code}{17}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 4.11}{17}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 4.12}{17}}
\@writefile{toc}{\contentsline {paragraph}{Huffman Codes}{17}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 4.5}{18}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 4.16}{18}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 4.17}{18}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 4.18}{18}}
\@writefile{toc}{\contentsline {paragraph}{Asymptotic Achievability of $H(X)$}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Redundancy of Prefix Codes}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Weak Typicality}{19}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 5.1 (Weak AEP I)}{19}}
\@writefile{toc}{\contentsline {paragraph}{Definition 5.2}{19}}
\@writefile{toc}{\contentsline {paragraph}{Empirical Entropy}{19}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 5.2 (Weak AEP II)}{20}}
\@writefile{toc}{\contentsline {paragraph}{The Source Coding Theorem}{20}}
\@writefile{toc}{\contentsline {paragraph}{Direct part:}{20}}
\@writefile{toc}{\contentsline {paragraph}{Converse:}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Strong Typicality}{21}}
\@writefile{toc}{\contentsline {paragraph}{Definition 6.1}{21}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.2 (Strong AEP)}{21}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.3}{21}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 6.4 (Chernoff Bound)}{22}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 6.5}{22}}
\@writefile{toc}{\contentsline {paragraph}{Definition 6.6}{22}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.7 (Consistency)}{22}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.8 (Preservation)}{22}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.9 (Strong JAEP)}{22}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 6.11}{22}}
\@writefile{toc}{\contentsline {paragraph}{Lemma}{23}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.10 (Conditional Strong AEP)}{23}}
\@writefile{toc}{\contentsline {paragraph}{Remark}{23}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 6.12}{23}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 6.13}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discrete Memoryless Channels}{23}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1 (Discrete Channel I)}{23}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.2 (Discrete Channel II)}{23}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.3}{23}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.4 (DMC I)}{24}}
\@writefile{toc}{\contentsline {paragraph}{Remark:}{24}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.5 (DMC II)}{24}}
\@writefile{toc}{\contentsline {paragraph}{Remark:}{24}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.6}{24}}
\@writefile{toc}{\contentsline {paragraph}{Remarks:}{25}}
\@writefile{toc}{\contentsline {paragraph}{Example 7.7 (Binary Symmetric Channel)}{25}}
\@writefile{toc}{\contentsline {paragraph}{Example 7.8 (Binary Erasure Channel)}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}The Channel Coding Theorem}{25}}
\@writefile{toc}{\contentsline {paragraph}{Direct Part}{25}}
\@writefile{toc}{\contentsline {paragraph}{Converse}{25}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.9}{25}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.10}{26}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.11}{26}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.12}{26}}
\@writefile{toc}{\contentsline {paragraph}{$P_{e}$ vs $\lambda _{\qopname  \relax m{max}}$}{26}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.13}{26}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.14}{26}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 7.15 (Channel Coding Theorem)}{26}}
\@writefile{toc}{\contentsline {paragraph}{Why $C$ is related to $I(X;Y)$?}{27}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 7.16}{27}}
\@writefile{toc}{\contentsline {paragraph}{Building Blocks of the Converse}{27}}
\@writefile{toc}{\contentsline {paragraph}{Converse}{28}}
\@writefile{toc}{\contentsline {paragraph}{Achievability}{28}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 7.17}{29}}
\@writefile{toc}{\contentsline {paragraph}{Random Coding Scheme}{29}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.18}{30}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.19}{30}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.20}{30}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 7.21}{30}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 7.22}{30}}
