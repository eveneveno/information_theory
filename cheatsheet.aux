\relax 
\providecommand\tcolorbox@label[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Information Measures}{1}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.1}{1}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.2 (Mutual Independence)}{1}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.3 (Pairwise Independence)}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.5}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.6 (Markov Chain)}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.7}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.8}{1}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.9}{2}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.10 (Markov subchains)}{2}}
\@writefile{toc}{\contentsline {paragraph}{Example 2.11}{2}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.12}{2}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.13}{2}}
\@writefile{toc}{\contentsline {paragraph}{Binary Entropy Function}{3}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.14}{3}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.15}{3}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.16}{3}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.17}{4}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.18}{4}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.19}{4}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.20}{4}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.21}{4}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.22}{4}}
\@writefile{toc}{\contentsline {paragraph}{Continuity of Shannon\IeC {\textquoteright }s Information Measures for Fixed Finite Alphabets}{4}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.23}{5}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.24 (Chain Rule for Entropy)}{5}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.25 (Chain Rule for Conditional Entropy)}{5}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.26 (Chain Rule for Mutual Information)}{5}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.27 (Chain Rule for Conditional Mutual Information)}{6}}
\@writefile{toc}{\contentsline {paragraph}{Definition 2.28}{6}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 2.29 (Fundamental Inequality)}{6}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 2.30}{6}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.31 (Divergence Inequality)}{6}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.32 (Log-Sum Inequality}{6}}
\@writefile{toc}{\contentsline {paragraph}{Example:}{6}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.33 (Pinsker's Inequality)}{7}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.34 (The Basic Inequalities)}{7}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.35}{7}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.36}{7}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 2.37}{7}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.38 (Conditioning Does Not Increase Entropy)}{7}}
\@writefile{toc}{\contentsline {paragraph}{Warning:}{7}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.39 (Independence Bound for Entropy)}{7}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 2.41}{7}}
\@writefile{toc}{\contentsline {paragraph}{Corollary}{7}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.42 (Data Processing Theorem)}{8}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.43}{8}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 2.44}{8}}
\@writefile{toc}{\contentsline {paragraph}{Remark}{8}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 2.47 (Fano's Inequality)}{8}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 2.48}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}The $I$-Measure}{8}}
\@writefile{toc}{\contentsline {paragraph}{Example}{8}}
\@writefile{toc}{\contentsline {paragraph}{Definition 3.1}{8}}
\@writefile{toc}{\contentsline {paragraph}{Definition 3.2}{8}}
\@writefile{toc}{\contentsline {paragraph}{Definition 3.4}{9}}
\@writefile{toc}{\contentsline {paragraph}{Example 3.5}{9}}
\@writefile{toc}{\contentsline {paragraph}{Construction of the $I$-Measure $\mu ^{*}$}{9}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 3.6}{9}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 3.7}{9}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 3.8}{9}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 3.9}{9}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 3.11}{10}}
\@writefile{toc}{\contentsline {paragraph}{Example 3.13 (Convexity of Mutual Information)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Example 3.14 (Concavity of Mutual Information)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Example 3.17 (Data Processing Theorem)}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {4}The Entropy Bound}{10}}
\@writefile{toc}{\contentsline {paragraph}{Definition 4.1}{10}}
\@writefile{toc}{\contentsline {paragraph}{Definition 4.2}{10}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 4.4 (Kraft Inequality)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Expected length of $\mathcal  {C}$}{10}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 4.6 (Entropy Bound)}{10}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 4.7}{10}}
\@writefile{toc}{\contentsline {paragraph}{Definition 4.8}{10}}
\@writefile{toc}{\contentsline {paragraph}{Definition 4.9}{11}}
\@writefile{toc}{\contentsline {paragraph}{Code Tree for Prefix Code}{11}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 4.11}{11}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 4.12}{11}}
\@writefile{toc}{\contentsline {paragraph}{Huffman Codes}{11}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 4.5}{11}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 4.16}{11}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 4.17}{11}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 4.18}{11}}
\@writefile{toc}{\contentsline {paragraph}{Asymptotic Achievability of $H(X)$}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Weak Typicality}{12}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 5.1 (Weak AEP I)}{12}}
\@writefile{toc}{\contentsline {paragraph}{Definition 5.2}{12}}
\@writefile{toc}{\contentsline {paragraph}{Empirical Entropy}{12}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 5.2 (Weak AEP II)}{12}}
\@writefile{toc}{\contentsline {paragraph}{The Source Coding Theorem}{13}}
\@writefile{toc}{\contentsline {paragraph}{Direct part:}{13}}
\@writefile{toc}{\contentsline {paragraph}{Converse:}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Strong Typicality}{13}}
\@writefile{toc}{\contentsline {paragraph}{Definition 6.1}{14}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.2 (Strong AEP)}{14}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.3}{14}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 6.4 (Chernoff Bound)}{14}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 6.5}{14}}
\@writefile{toc}{\contentsline {paragraph}{Definition 6.6}{14}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.7 (Consistency)}{14}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.8 (Preservation)}{14}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.9 (Strong JAEP)}{15}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 6.11}{15}}
\@writefile{toc}{\contentsline {paragraph}{Lemma}{15}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 6.10 (Conditional Strong AEP)}{15}}
\@writefile{toc}{\contentsline {paragraph}{Remark}{15}}
\@writefile{toc}{\contentsline {paragraph}{Corollary 6.12}{15}}
\@writefile{toc}{\contentsline {paragraph}{Proposition 6.13}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discrete Memoryless Channels}{15}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.1 (Discrete Channel I)}{15}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.2 (Discrete Channel II)}{16}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.3}{16}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.4 (DMC I)}{16}}
\@writefile{toc}{\contentsline {paragraph}{Remark:}{16}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.4 (DMC I)}{16}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.5 (DMC II)}{16}}
\@writefile{toc}{\contentsline {paragraph}{Remark:}{16}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.6}{16}}
\@writefile{toc}{\contentsline {paragraph}{Remarks:}{17}}
\@writefile{toc}{\contentsline {paragraph}{The Channel Coding Theorem}{17}}
\@writefile{toc}{\contentsline {paragraph}{Direct Part}{17}}
\@writefile{toc}{\contentsline {paragraph}{Converse}{17}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.9}{17}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.10}{17}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.11}{17}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.12}{17}}
\@writefile{toc}{\contentsline {paragraph}{$P_{e}$ vs $\lambda _{\qopname  \relax m{max}}$}{18}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.13}{18}}
\@writefile{toc}{\contentsline {paragraph}{Definition 7.14}{18}}
\@writefile{toc}{\contentsline {paragraph}{Theorem 7.15 (Channel Coding Theorem)}{18}}
\@writefile{toc}{\contentsline {paragraph}{Why $C$ is related to $I(X;Y)$?}{18}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 7.16}{19}}
\@writefile{toc}{\contentsline {paragraph}{Building Blocks of the Converse}{19}}
\@writefile{toc}{\contentsline {paragraph}{Converse}{19}}
\@writefile{toc}{\contentsline {paragraph}{Achievability}{20}}
\@writefile{toc}{\contentsline {paragraph}{Lemma 7.17}{20}}
\@writefile{toc}{\contentsline {paragraph}{Random Coding Scheme}{21}}
